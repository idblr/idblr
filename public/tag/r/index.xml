<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R | Ian Buller</title>
    <link>/tag/r/</link>
      <atom:link href="/tag/r/index.xml" rel="self" type="application/rss+xml" />
    <description>R</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© Ian Buller, 2020 &amp;middot; Opinions expressed are my own</copyright><lastBuildDate>Sat, 16 May 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/avatar.jpg</url>
      <title>R</title>
      <link>/tag/r/</link>
    </image>
    
    <item>
      <title>Cumulative SARS-CoV-2 Cases in the District of Columbia by Health Planning Neighborhoods</title>
      <link>/post/2020-05-15-covid-dc/covid-dc/</link>
      <pubDate>Sat, 16 May 2020 00:00:00 +0000</pubDate>
      <guid>/post/2020-05-15-covid-dc/covid-dc/</guid>
      <description>


&lt;p&gt;After moving to DC last year, &lt;a href=&#34;https://twitter.com/PoPville&#34;&gt;PoPville&lt;/a&gt; has been a personal favorite for local scoop. A post on &lt;a href=&#34;https://www.popville.com/2020/05/dc-neighborhood-covid-coronavirus-map-population/#more-234053&#34;&gt;May 11, 2020&lt;/a&gt; captured my attention. Molly Tolzmann &lt;a href=&#34;https://twitter.com/zmotoly&#34;&gt;zmotoly&lt;/a&gt; adjusted the daily &lt;a href=&#34;https://coronavirus.dc.gov/page/coronavirus-data&#34;&gt;coronavirus data&lt;/a&gt; publicly released by the DC Mayoral Office at the &lt;a href=&#34;https://opendata.dc.gov/datasets/dc-health-planning-neighborhoods&#34;&gt;DC health planning neighborhood level&lt;/a&gt; by the 2018 American Community Survey (ACS) census tract data and demographic data from &lt;a href=&#34;https://opendata.dc.gov/&#34;&gt;OpenData DC&lt;/a&gt;. This post is a replication of the data visualization using &lt;a href=&#34;https://cran.r-project.org/&#34;&gt;R&lt;/a&gt; and can be found on a public &lt;a href=&#34;https://github.com/idblr/coviDC&#34;&gt;GitHub repository&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Imporant Notes&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The following show cumulative case rate per 1,000 since the beginning of the COVID-19 outbreak in DC. Therefore, the the stats do not reflect the number of people currently infected with SARS-CoV-2.&lt;/li&gt;
&lt;li&gt;The following &lt;em&gt;does not&lt;/em&gt; account for the degree of COVID-19 testing in each neighborhood.&lt;/li&gt;
&lt;/ul&gt;
&lt;center&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://s26552.pcdn.co/wp-content/uploads/2020/05/IMAGE-May-9-DC-neighborhood-COVID-positive-rate.jpg&#34; alt=&#34;COVID-19 in DC by @zmotoly&#34; width=&#34;400&#34; /&gt;
&lt;p class=&#34;caption&#34;&gt;COVID-19 in DC by &lt;span class=&#34;citation&#34;&gt;@zmotoly&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/center&gt;
&lt;p&gt;The following are the necessary packages and settings for the exercise.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Packages
loadedPackages &amp;lt;- c(&amp;quot;broom&amp;quot;, &amp;quot;geojsonio&amp;quot;, &amp;quot;ggplot2&amp;quot;, &amp;quot;googlesheets4&amp;quot;, &amp;quot;htmlwidgets&amp;quot;, &amp;quot;leaflet&amp;quot;, &amp;quot;sp&amp;quot;, &amp;quot;stringr&amp;quot;)
invisible(lapply(loadedPackages, require, character.only = T))

# Settings
googlesheets4::gs4_deauth() # no Google authorization necessary because we are not reading a public repo&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We import the District of Columbia &lt;a href=&#34;https://opendata.dc.gov/datasets/acs-2018-population-variables-tract/data&#34;&gt;Health Planning Neighborhoods&lt;/a&gt; boundaries and Molly Tolzmann’s &lt;a href=&#34;https://twitter.com/zmotoly&#34;&gt;zmotoly&lt;/a&gt; collation of the cumulative cases from start of the SARS-CoV-2 outbreak. The latter is hosted on a public &lt;a href=&#34;%22https://docs.google.com/spreadsheets/d/1u-FlJe2B1rYV0obEosHBks9utkU30-C2TSkHka6AVS8/edit#gid=1923705378%22&#34;&gt;Google Sheet&lt;/a&gt; and is accessible in &lt;code&gt;R&lt;/code&gt; using the &lt;a href=&#34;https://github.com/tidyverse/googlesheets4&#34;&gt;googlesheets4 package&lt;/a&gt;. After cleaning up the column names of the disease data, we merge the two data sets together and spatially project the polygons contained in the data to &lt;a href=&#34;https://epsg.io/32618&#34;&gt;EPSG:32618&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# District of Columbia Health Planning Neighborhoods
gis_path &amp;lt;- &amp;quot;https://opendata.arcgis.com/datasets/de63a68eb7674548ae0ac01867123f7e_13.geojson&amp;quot;
dc &amp;lt;- geojsonio::geojson_read(gis_path,  what = &amp;quot;sp&amp;quot;)

# District of Columbia SAR-CoV-2 Data prepared by @zmotoly
covid_path &amp;lt;- &amp;quot;https://docs.google.com/spreadsheets/d/1u-FlJe2B1rYV0obEosHBks9utkU30-C2TSkHka6AVS8/edit#gid=1923705378&amp;quot;
covid &amp;lt;- googlesheets4::read_sheet(ss = covid_path,
                                   sheet = 2, # second sheet
                                   skip = 1)  # skip 1st row of annotation
names(covid) &amp;lt;- sub(&amp;quot;\n&amp;quot;, &amp;quot;&amp;quot;, names(covid))   # remove extra line in column names
names(covid) &amp;lt;- gsub(&amp;quot; &amp;quot;, &amp;quot;_&amp;quot;, names(covid))  # replace spaces with underscore

# Merge
dc_covid &amp;lt;- sp::merge(dc, covid, by.x = &amp;quot;CODE&amp;quot;, by.y = &amp;quot;NB_Code&amp;quot;)

# Spatial Projection
## UTM zone 18N (Washington, DC)
dc_covid_proj &amp;lt;- sp::spTransform(dc_covid, CRS(&amp;quot;+init=EPSG:32618&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;static-map&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Static Map&lt;/h3&gt;
&lt;p&gt;We can then plot the cumulative rate using various plotting techniques. Here, I demonstrate the &lt;a href=&#34;https://github.com/tidyverse/ggplot2&#34;&gt;ggplot2 package&lt;/a&gt;. First, we convert the &lt;code&gt;dc_covid_proj&lt;/code&gt; object of class &lt;code&gt;SpatialPolygonsDataFrame&lt;/code&gt; to a class &lt;code&gt;tibble&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Uses ggplot2 package
## helpful material: https://cengel.github.io/rspatial/4_Mapping.nb.html
## Data preparation, ggplot2 requires a data.frame
dc_covid_df &amp;lt;- broom::tidy(dc_covid_proj) # convert to tidy data frame
dc_covid_proj$polyID &amp;lt;- sapply(slot(dc_covid_proj, &amp;quot;polygons&amp;quot;), function(x) slot(x, &amp;quot;ID&amp;quot;)) # preserve polygon id
CoV_DC_df &amp;lt;- merge(dc_covid_df, dc_covid_proj, by.x = &amp;quot;id&amp;quot;, by.y=&amp;quot;polyID&amp;quot;) # merge data&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we can customize our plot in various ways. Here I present cumulative cases per 1,000 (May 15, since start of the outbreak) choosing a &lt;a href=&#34;https://blog.mapbox.com/7-best-practices-for-mapping-a-pandemic-9f203576a132?gi=6907699c528e&#34;&gt;non-alarmist color palette&lt;/a&gt; from &lt;a href=&#34;https://colorbrewer2.org/&#34;&gt;ColorBrewer2.0&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Plot of cumulative cases per 1,000
ggplot2::ggplot() +                                             # initialize ggplot object
  ggplot2::geom_polygon(                                        # make a polygon
    data = CoV_DC_df,                                           # data frame
    ggplot2::aes(x = long, y = lat, group = group,              # coordinates, and group them by polygons
                 fill = ggplot2::cut_interval(Cases_per_1000_May_15, 10)),       # variable to use for filling
    colour = &amp;quot;white&amp;quot;) +                                         # color of polygon borders
  ggplot2::scale_fill_brewer(&amp;quot;Cumulative cases per 1,000&amp;quot;,      # title of colorkey 
                             palette = &amp;quot;Purples&amp;quot;,               # fill with brewer colors 
                             na.value = &amp;quot;grey67&amp;quot;,               # color for NA (The National Mall)
                             direction = 1,                     # reverse colors in colorkey
                             guide = ggplot2::guide_legend(reverse = T)) +  # reverse order of colokey
  ggplot2::ggtitle(&amp;quot;Cumulative SARS-CoV-2 cases per 1,000 (March 7, 2020 - May 15, 2020)&amp;quot;) + # add title
  ggplot2::theme(line = ggplot2::element_blank(),               # remove axis lines
                 axis.text = ggplot2::element_blank(),          # remove tickmarks
                 axis.title = ggplot2::element_blank(),         # remove axis labels
                 panel.background = ggplot2::element_blank(),   # remove background gridlines
                 text = ggplot2::element_text(size = 10)) +     # set font size
  ggplot2::coord_equal()                                        # both axes the same scale&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-15-covid-dc/2020-05-15-covid-dc_files/figure-html/cumulative%20rate-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;interactive-map&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Interactive Map&lt;/h3&gt;
&lt;p&gt;In addition to a static map, the &lt;a href=&#34;https://github.com/rstudio/leaflet&#34;&gt;leaflet package&lt;/a&gt; provides capabilities to create an interactive map with customizable features such as basemaps and overlapping layers. First, we need to spatially project the data to &lt;a href=&#34;https://epsg.io/4326&#34;&gt;EPSG:4326&lt;/a&gt;. We can also create custom popups when scrolling mouse over each neighborhood. Here, I use the same color palette as the static map and provide an example of the raw cumulative cases (May 15, 2020) in DC to demonstrate the layer overlapping feature of the &lt;code&gt;leaflet&lt;/code&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Work with unprojected spatialpolygonsdataframe
## Project to WGS84 EPSG:4326
CoV_DC_WGS84 &amp;lt;- sp::spTransform(dc_covid_proj, CRS(&amp;quot;+init=epsg:4326&amp;quot;))

## Create Popups
dc_health &amp;lt;- stringr::str_to_title(CoV_DC_WGS84$Neighborhood_Name)
dc_health[c(11,25,41,49)] &amp;lt;- c(&amp;quot;DC Medical Center&amp;quot;, &amp;quot;GWU&amp;quot;, &amp;quot;National Mall&amp;quot;, &amp;quot;SW/Waterfront&amp;quot; )
CoV_DC_WGS84$popup1 &amp;lt;- paste(dc_health, &amp;quot;: &amp;quot;,
                             format(round(CoV_DC_WGS84$Total_cases_May_15, digits = 0), big.mark = &amp;quot;,&amp;quot;, trim = T),
                             &amp;quot; cumulative cases&amp;quot;, sep = &amp;quot;&amp;quot;)
CoV_DC_WGS84$popup2 &amp;lt;- paste(dc_health, &amp;quot;: &amp;quot;,
                             format(round(CoV_DC_WGS84$Cases_per_1000_May_15, digits = 0), big.mark = &amp;quot;,&amp;quot;, trim = T),
                             &amp;quot; cumulative cases per 1,000&amp;quot;, sep = &amp;quot;&amp;quot;)

## Set Palettes
pal_cum &amp;lt;- leaflet::colorNumeric(palette = &amp;quot;Purples&amp;quot;,
                                 domain = CoV_DC_WGS84$Total_cases_May_15,
                                 na.color = &amp;quot;#555555&amp;quot;)
pal_rate &amp;lt;- leaflet::colorNumeric(palette = &amp;quot;Purples&amp;quot;,
                                  domain = CoV_DC_WGS84$Cases_per_1000_May_15,
                                  na.color = &amp;quot;#555555&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The following is code for the leaflet plot. I set the starting parameters including available basemaps and then add each layer of COVID-19 data as polygons. After specifying the legend for each layer I finish up with a mini map to show scale.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Create leaflet plot
dc_m1 &amp;lt;- leaflet::leaflet(CoV_DC_WGS84, width = &amp;quot;100%&amp;quot;) %&amp;gt;%                        # initial data
  leaflet::setView(lng = -77, lat = 38.9, zoom = 11) %&amp;gt;%                           # starting coordinates
  leaflet::addProviderTiles(providers$OpenStreetMap, group = &amp;quot;OSM (Default)&amp;quot;) %&amp;gt;%  # default basemap
  leaflet::addProviderTiles(providers$Esri.WorldTopoMap, group = &amp;quot;Terrain&amp;quot;) %&amp;gt;%    # additional basemap
  leaflet::addProviderTiles(providers$OpenTopoMap, group = &amp;quot;Roads&amp;quot;) %&amp;gt;%            # additional basemap
  leaflet::addPolygons(data = CoV_DC_WGS84, color = &amp;quot;black&amp;quot;, weight = 1, smoothFactor = 0.5, opacity = 1,
                       fillOpacity = 0.67, fillColor = ~pal_cum(Total_cases_May_15), popup = ~popup1,
                       highlightOptions = highlightOptions(color = &amp;quot;white&amp;quot;, weight = 2, bringToFront = TRUE),
                       group = &amp;quot;Cumulative Cases&amp;quot;) %&amp;gt;%
  leaflet::addPolygons(data = CoV_DC_WGS84, color = &amp;quot;black&amp;quot;, weight = 1, smoothFactor = 0.5, opacity = 1,
                       fillOpacity = 0.67, fillColor = ~pal_rate(Cases_per_1000_May_15), popup = ~popup2,
                       highlightOptions = highlightOptions(color = &amp;quot;white&amp;quot;, weight = 2, bringToFront = TRUE),
                       group = &amp;quot;Cumulative Rate&amp;quot;) %&amp;gt;%
  leaflet::addLayersControl(baseGroups = c(&amp;quot;OSM (Default)&amp;quot;, &amp;quot;Terrain&amp;quot;, &amp;quot;Roads&amp;quot;),
                            overlayGroups = c(&amp;quot;Cumulative Cases&amp;quot;, &amp;quot;Cumulative Rate&amp;quot;),
                            options = layersControlOptions(collapsed = FALSE)) %&amp;gt;% # layer selection
  addLegend(&amp;quot;topright&amp;quot;, pal = pal_cum, values = ~Total_cases_May_15,
            title = &amp;quot;Cumulative Cases&amp;quot;, opacity = 1, group = &amp;quot;Cumulative Cases&amp;quot;) %&amp;gt;%
  addLegend(&amp;quot;topright&amp;quot;, pal = pal_rate, values = ~Cases_per_1000_May_15, 
            title = &amp;quot;Cumulative Rate per 1,000&amp;quot;, opacity = 1, group = &amp;quot;Cumulative Rate&amp;quot;) %&amp;gt;%
  leaflet::hideGroup(c(&amp;quot;Cumulative Cases&amp;quot;, &amp;quot;Cumulative Rate&amp;quot;)) %&amp;gt;% # no data shown (default)
  leaflet::addMiniMap(position = &amp;quot;bottomleft&amp;quot;) # add mini map&lt;/code&gt;&lt;/pre&gt;
&lt;iframe seamless src=&#34;leafmap.html&#34; width=&#34;100%&#34; height=&#34;400&#34;&gt;
&lt;/iframe&gt;
&lt;p&gt;As of May 15, 2020 the highest cumulative rate of SARS-CoV-2 cases have occurred in the Stadium Armory and Molly Tolzmann &lt;a href=&#34;https://twitter.com/zmotoly&#34;&gt;zmotoly&lt;/a&gt; noted the DC Jail is located in this neighborhood in &lt;a href=&#34;https://www.popville.com/2020/05/dc-neighborhood-covid-coronavirus-map-population/#more-234053&#34;&gt;her original post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The provided maps are not intended to inform decision-making. Instead, I provide the the &lt;a href=&#34;https://github.com/idblr/coviDC&#34;&gt;open-source code&lt;/a&gt; to download, manage, and visualize publicly available data. Future steps include linking other demographic information to each DC Health Planning Neighborhood (e.g., housing occupancy) and assessing their relationships with disease occurrence or creating an automatic workflow to update these figures daily.&lt;/p&gt;
&lt;p&gt;Thanks, again, to Molly Tolzmann &lt;a href=&#34;https://twitter.com/zmotoly&#34;&gt;zmotoly&lt;/a&gt; and &lt;a href=&#34;https://twitter.com/PoPville&#34;&gt;PoPville&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Areas of a spatial segregation model significantly different from null expectations</title>
      <link>/post/2020-05-10-pval-spatseg/asymptotic-p-values-for-spatial-segregation-model/</link>
      <pubDate>Tue, 12 May 2020 00:00:00 +0000</pubDate>
      <guid>/post/2020-05-10-pval-spatseg/asymptotic-p-values-for-spatial-segregation-model/</guid>
      <description>
&lt;script src=&#34;/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;I present code to identify areas of a spatial segregation model that exceed our null expectations using the &lt;a href=&#34;https://github.com/spatstat/spatstat/blob/master/man/relrisk.Rd&#34;&gt;relrisk&lt;/a&gt; function in the &lt;a href=&#34;https://github.com/spatstat/spatstat&#34;&gt;spatstat&lt;/a&gt; package and an assumption of normality of the estimated probabilities. A spatial segregation model was originally proposed by &lt;a href=&#34;https://doi.org/10.1111/j.1467-9876.2005.05373.x&#34;&gt;Diggle, Zheng, &amp;amp; Durr in 2005&lt;/a&gt; which estimates spatially-varying probabilities of an event of a certain type to occur in an area accounting for other types. The original method uses a Monte Carlo-based simulation, which is computationally expensive. Instead, &lt;a href=&#34;https://github.com/baddstats&#34;&gt;Adrian Baddeley&lt;/a&gt; and the spatstat team adapted the &lt;a href=&#34;https://github.com/spatstat/spatstat/blob/master/man/relrisk.Rd&#34;&gt;relrisk&lt;/a&gt; function for a multitype (m &amp;gt; 2) point pattern that has an option to compute the standard error of the probability estimates based on asymptotic theory, assuming a Poisson process.&lt;/p&gt;
&lt;p&gt;Here, I use the standard errors to compute a 95% confidence interval (CI) at all gridded pixels (“knots”) for each type. Knots with a CI that does not capture the null expectation for each type are identified. I use the provided &lt;code&gt;lansing&lt;/code&gt; dataset from the &lt;a href=&#34;https://github.com/spatstat/spatstat.data&#34;&gt;spatstat.data&lt;/a&gt; package. Created with assistance from &lt;a href=&#34;https://sph.emory.edu/faculty/profile/index.php?FID=345&#34;&gt;Dr. Lance Waller&lt;/a&gt; and &lt;a href=&#34;http://barry.rowlingson.com/&#34;&gt;Barry Rowlingson&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Packages
  library(spatstat)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Data
  spatstat.data::lansing&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Marked planar point pattern: 2251 points
## Multitype, with levels = blackoak, hickory, maple, misc, redoak, whiteoak 
## window: rectangle = [0, 1] x [0, 1] units (one unit = 924 feet)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Convert the lansing data to a ppp object
  ppp_lansing &amp;lt;- spatstat::ppp(x = spatstat.data::lansing$x, 
                             y = spatstat.data::lansing$y,
                             window = spatstat::unit.square(),
                             marks = as.factor(spatstat::marks(spatstat.data::lansing)))

# Plot input
  spatstat::plot.ppp(ppp_lansing, main = &amp;quot;Lansing Woods&amp;quot;, cex = 0.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-10-pval-spatseg/2020-05-10-asymptotic-p-values-for-spatial-segregation-model_files/figure-html/data-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Estimate nonparametric spatially-varying probabilities of type
  f1 &amp;lt;- spatstat::relrisk.ppp(ppp_lansing, casecontrol = F, diggle = T, se = T, sigma = bw.diggle)
  
# Default plots
  plot(f1$estimate, main = &amp;quot;Probability of an event by type&amp;quot;, zlim = c(0,1)) # probabilities&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-10-pval-spatseg/2020-05-10-asymptotic-p-values-for-spatial-segregation-model_files/figure-html/spatial%20segregration-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;  plot(f1$SE, main = &amp;quot;Standard error of probability&amp;quot;, zlim = c(0,0.03)) # standard errors&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-10-pval-spatseg/2020-05-10-asymptotic-p-values-for-spatial-segregation-model_files/figure-html/spatial%20segregration-2.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;  wh &amp;lt;- spatstat::im.apply(f1$estimate, which.max)
  types &amp;lt;- levels(spatstat::marks(spatstat.data::lansing))
  wh &amp;lt;- spatstat::eval.im(types[wh]) # most common 
  spatstat::plot.im(wh, main=&amp;quot;Most common species&amp;quot;, ribargs = list(las = 1))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-10-pval-spatseg/2020-05-10-asymptotic-p-values-for-spatial-segregation-model_files/figure-html/spatial%20segregration-3.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Significant p-values assumming normality of the Poisson process
## relrisk() computes standard errors based on asymptotic theory, assuming a Poisson process
  alpha &amp;lt;- 0.05                           # alpha
  z &amp;lt;- qnorm(alpha/2, lower.tail = F)     # z-statistic
  f1$u &amp;lt;- f1$estimate + z*f1$SE           # Upper CIs
  f1$l &amp;lt;- f1$estimate - z*f1$SE           # Lower CIs
  mu_0 &amp;lt;- as.vector(table(spatstat::marks(ppp_lansing))/ppp_lansing$n) # null expectations by type
  f1$p &amp;lt;- f1$estimate # copy structure of pixels, replace values
  for (i in 1:length(f1$p)) {
    f1$p[[i]]$v &amp;lt;- factor(ifelse(mu_0[i] &amp;gt; f1$u[[i]]$v, &amp;quot;lower&amp;quot;,
                                 ifelse( mu_0[i] &amp;lt; f1$l[[i]]$v, &amp;quot;higher&amp;quot;, &amp;quot;none&amp;quot;)),
                          levels = c(&amp;quot;lower&amp;quot;, &amp;quot;none&amp;quot;, &amp;quot;higher&amp;quot;))
  }

  # Plot significant p-values
  plot(f1$p, main = &amp;quot;Significant difference from null?&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-05-10-pval-spatseg/2020-05-10-asymptotic-p-values-for-spatial-segregation-model_files/figure-html/spatial%20segregration-4.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The final plot identifies where the spatially-varying probabilities exceed the null expected probability of each type. Areas of higher-than-expected probability could be considered “hot-spots” and areas of lower-than-expected probability could be considered “cold-spots.” Areas that are not significantly different from the null expectation could suggest additional sampling is necessary to determine if these areas are hot are cold spots.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
